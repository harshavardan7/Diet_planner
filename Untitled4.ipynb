{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fdb504f-57bd-4f0d-8011-0ad2851d865d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m     src \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(class_path, image)\n\u001b[0;32m     34\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(train_dir, class_name, image)\n\u001b[1;32m---> 35\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopyfile(src, dst)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Move validation images\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m validation_images:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\shutil.py:258\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(src, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 258\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    259\u001b[0m             \u001b[38;5;66;03m# macOS\u001b[39;00m\n\u001b[0;32m    260\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m _HAS_FCOPYFILE:\n\u001b[0;32m    261\u001b[0m                 \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Original data path\n",
    "data_path = r'C:\\Users\\17har\\Downloads\\archive (8)\\Food Classification'\n",
    "\n",
    "# Define paths for training and validation sets\n",
    "base_dir = 'food_data_split'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Create directories for train and validation\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(validation_dir, exist_ok=True)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "for class_name in os.listdir(data_path):\n",
    "    class_path = os.path.join(data_path, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        images = os.listdir(class_path)\n",
    "        train_images, validation_images = train_test_split(images, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Create class directories in train and validation directories\n",
    "        os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "        os.makedirs(os.path.join(validation_dir, class_name), exist_ok=True)\n",
    "        \n",
    "        # Move training images\n",
    "        for image in train_images:\n",
    "            src = os.path.join(class_path, image)\n",
    "            dst = os.path.join(train_dir, class_name, image)\n",
    "            shutil.copyfile(src, dst)\n",
    "        \n",
    "        # Move validation images\n",
    "        for image in validation_images:\n",
    "            src = os.path.join(class_path, image)\n",
    "            dst = os.path.join(validation_dir, class_name, image)\n",
    "            shutil.copyfile(src, dst)\n",
    "\n",
    "# Data generators for loading and augmenting data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Flow from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Save the class indices to a file\n",
    "with open('class_indices.json', 'w') as f:\n",
    "    json.dump(train_generator.class_indices, f)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(150, 150, 3)),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=30,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('food_classification_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba59e80-aeba-4ee6-9673-41e3711c8a31",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Registering two acd_resource_resolvers with name 'tpu_replicated_input_resolver'! (Previous registration was in register C:\\\\Users\\\\17har\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\framework\\\\registry.py:65)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image \u001b[38;5;28;01mas\u001b[39;00m keras_image\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py:45\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf2 \u001b[38;5;28;01mas\u001b[39;00m _tf2\n\u001b[0;32m     43\u001b[0m _tf2\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __operators__\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m audio\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\__init__.py:11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decorator\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dispatch\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m eager_context\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature_column\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m combinations\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m interim\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\_api\\v2\\__internal__\\distribute\\combinations\\__init__.py:8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"Public API for tf._api.v2.__internal__.distribute.combinations namespace\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m env \u001b[38;5;66;03m# line: 456\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generate \u001b[38;5;66;03m# line: 365\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcombinations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_main_process \u001b[38;5;66;03m# line: 418\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\combinations.py:33\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m session\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m collective_all_reduce_strategy\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute_lib\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_process_runner\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\collective_all_reduce_strategy.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_lib\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_util\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mirrored_strategy\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m multi_worker_util\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy_dataset\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\mirrored_strategy.py:34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m values_util\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tfconfig_cluster_resolver\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_lib \u001b[38;5;28;01mas\u001b[39;00m input_lib_v1\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\cluster_resolver\\__init__.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mslurm_cluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SlurmClusterResolver\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtfconfig_cluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFConfigClusterResolver\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu_cluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TPUClusterResolver\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\cluster_resolver\\tpu_cluster_resolver.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Shim so that direct imports of tpu_cluster_resolver get correct symbols.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu_cluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialize_tpu_system\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu_cluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_running_in_gce  \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistribute\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster_resolver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu_cluster_resolver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m shutdown_tpu_system\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\distribute\\cluster_resolver\\tpu\\tpu_cluster_resolver.py:26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m errors\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging \u001b[38;5;28;01mas\u001b[39;00m logging\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tpu_strategy_util\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tpu_system_metadata \u001b[38;5;28;01mas\u001b[39;00m tpu_system_metadata_lib\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m server_lib\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\tpu\\tpu_strategy_util.py:30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_logging \u001b[38;5;28;01mas\u001b[39;00m logging\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m topology\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpu\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tpu\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m compat\n\u001b[0;32m     34\u001b[0m _INITIALIZED_TPU_SYSTEMS \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\tpu\\tpu.py:184\u001b[0m\n\u001b[0;32m    180\u001b[0m     shutdown_distributed_tpu \u001b[38;5;241m=\u001b[39m tpu_ops\u001b[38;5;241m.\u001b[39mshutdown_distributed_tpu()\n\u001b[0;32m    181\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m shutdown_distributed_tpu\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;129m@auto_control_deps\u001b[39m\u001b[38;5;241m.\u001b[39mregister_acd_resource_resolver\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtpu_replicated_input_resolver\u001b[39m(\n\u001b[0;32m    186\u001b[0m     op: ops\u001b[38;5;241m.\u001b[39mOperation,\n\u001b[0;32m    187\u001b[0m     resource_reads: object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet,\n\u001b[0;32m    188\u001b[0m     resource_writes: object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m    189\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Replaces TPUReplicatedInput outputs with its inputs in resource_inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m   \u001b[38;5;66;03m# Ignore TPUReplicatedInput for ACD purposes since we will be directly adding\u001b[39;00m\n\u001b[0;32m    191\u001b[0m   \u001b[38;5;66;03m# control deps on the replicated inputs.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\auto_control_deps.py:583\u001b[0m, in \u001b[0;36mregister_acd_resource_resolver\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregister_acd_resource_resolver\u001b[39m(f):\n\u001b[0;32m    550\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Register a function for resolving resources touched by an op.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \n\u001b[0;32m    552\u001b[0m \u001b[38;5;124;03m  `f` is called for every Operation added in the ACD context with the op's\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[38;5;124;03m    The function `f` after adding it to the registry.\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 583\u001b[0m   _acd_resource_resolvers_registry\u001b[38;5;241m.\u001b[39mregister(f)\n\u001b[0;32m    584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\framework\\registry.py:57\u001b[0m, in \u001b[0;36mRegistry.register\u001b[1;34m(self, candidate, name)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry:\n\u001b[0;32m     56\u001b[0m   frame \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry[name][_LOCATION_TAG]\n\u001b[1;32m---> 57\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistering two \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m! \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     59\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Previous registration was in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m     60\u001b[0m       (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, name, frame\u001b[38;5;241m.\u001b[39mname, frame\u001b[38;5;241m.\u001b[39mfilename, frame\u001b[38;5;241m.\u001b[39mlineno))\n\u001b[0;32m     62\u001b[0m logging\u001b[38;5;241m.\u001b[39mvlog(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRegistering \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, candidate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name)\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# stack trace is [this_function, Register(), user_function,...]\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# so the user function is #2.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Registering two acd_resource_resolvers with name 'tpu_replicated_input_resolver'! (Previous registration was in register C:\\\\Users\\\\17har\\\\anaconda3\\\\Lib\\\\site-packages\\\\tensorflow\\\\python\\\\framework\\\\registry.py:65)\""
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load your trained model\n",
    "model = tf.keras.models.load_model('food_classification_model.keras', compile=False)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load the class indices\n",
    "with open('class_indices.json', 'r') as f:\n",
    "    class_indices = json.load(f)\n",
    "\n",
    "# Reverse the class indices dictionary to map indices to class labels\n",
    "class_indices = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def load_and_preprocess_image(img_path):\n",
    "    try:\n",
    "        img = keras_image.load_img(img_path, target_size=(150, 150))\n",
    "        img_array = keras_image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array /= 255.0\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image from {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image_class(model, img_array, class_indices):\n",
    "    if img_array is None:\n",
    "        return \"Unknown\"\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    predicted_class_label = class_indices.get(predicted_class_index, \"Unknown\")\n",
    "    return predicted_class_label\n",
    "\n",
    "# Calorie map for each class\n",
    "calorie_map = {\n",
    "    'samosa': 250,\n",
    "    'pizza': 300,\n",
    "    'burger': 500,\n",
    "    'idli':150,\n",
    "    'kulfi':206\n",
    "}\n",
    "\n",
    "# Function to calculate recommended calories\n",
    "def get_recommended_calories(age, gender, height, weight, activity_level, goal):\n",
    "    if gender.lower() == 'male':\n",
    "        bmr = 10 * weight + 6.25 * height - 5 * age + 5\n",
    "    else:\n",
    "        bmr = 10 * weight + 6.25 * height - 5 * age - 161\n",
    "\n",
    "    activity_factors = {\n",
    "        'sedentary': 1.2,\n",
    "        'lightly active': 1.375,\n",
    "        'moderately active': 1.55,\n",
    "        'very active': 1.725,\n",
    "        'super active': 1.9\n",
    "    }\n",
    "\n",
    "    tdee = bmr * activity_factors[activity_level.lower()]\n",
    "\n",
    "    if goal.lower() == 'lose weight':\n",
    "        recommended_calories = tdee - 500\n",
    "    elif goal.lower() == 'gain weight':\n",
    "        recommended_calories = tdee + 500\n",
    "    else:\n",
    "        recommended_calories = tdee\n",
    "\n",
    "    return recommended_calories\n",
    "\n",
    "# Function to calculate calorie difference\n",
    "def calculate_calorie_difference(recommended_calories, consumed_calories):\n",
    "    return recommended_calories - consumed_calories\n",
    "\n",
    "# Function to provide dietary recommendation\n",
    "def provide_dietary_recommendation(calorie_difference):\n",
    "    if calorie_difference > 0:\n",
    "        return \"You have remaining calories for the day. Consider consuming a balanced meal with proteins, carbohydrates, and fats.\"\n",
    "    elif calorie_difference < 0:\n",
    "        return \"You have exceeded your calorie intake for the day. Consider light snacks or low-calorie foods for the rest of the day.\"\n",
    "    else:\n",
    "        return \"You have met your calorie intake for the day. Maintain a balanced diet.\"\n",
    "\n",
    "# Example user info\n",
    "name = \"John Doe\"\n",
    "age = 30\n",
    "gender = \"male\"\n",
    "height = 175  # in cm\n",
    "weight = 70   # in kg\n",
    "activity_level = \"moderately active\"\n",
    "goal = \"maintain weight\"\n",
    "\n",
    "# Path to the image of the dish\n",
    "img_path = r'C:\\Users\\17har\\Downloads\\archive (8)\\Food Classification\\samosa\\255.jpg'\n",
    "\n",
    "# Load and preprocess the image\n",
    "img_array = load_and_preprocess_image(img_path)\n",
    "\n",
    "# Predict the class of the dish\n",
    "predicted_class = predict_image_class(model, img_array, class_indices)\n",
    "\n",
    "# Get the calories for the predicted class\n",
    "consumed_calories = calorie_map.get(predicted_class, 0)\n",
    "\n",
    "# Get the user's recommended calories\n",
    "recommended_calories = get_recommended_calories(age, gender, height, weight, activity_level, goal)\n",
    "\n",
    "# Calculate the calorie difference\n",
    "calorie_difference = calculate_calorie_difference(recommended_calories, consumed_calories)\n",
    "\n",
    "# Provide dietary recommendation\n",
    "dietary_recommendation = provide_dietary_recommendation(calorie_difference)\n",
    "\n",
    "print(f'The image is classified as: {predicted_class}')\n",
    "print(f'Calories in the dish: {consumed_calories}')\n",
    "print(f'Recommended daily calorie intake: {recommended_calories}')\n",
    "print(f'Calorie difference: {calorie_difference}')\n",
    "print(f'Dietary recommendation: {dietary_recommendation}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f585048d-7e4f-448a-a0c3-2b08affadc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\17har\\anaconda3\\lib\\site-packages (1.30.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<8,>=1.4 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (7.0.1)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=6.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (13.3.5)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (4.9.0)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (2.1)\n",
      "Requirement already satisfied: validators<1,>=0.2 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (0.18.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from streamlit) (2.1.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\17har\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\17har\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from importlib-metadata<8,>=1.4->streamlit) (3.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from validators<1,>=0.2->streamlit) (5.1.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\17har\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f979758-609a-4eae-b0a1-b98a943a0325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diet_planner_app.py has been created.\n"
     ]
    }
   ],
   "source": [
    "# Define the content of the Streamlit app\n",
    "streamlit_app_code = r\"\"\"\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Set default encoding to utf-8\n",
    "sys.stdout.reconfigure(encoding='utf-8')\n",
    "sys.stderr.reconfigure(encoding='utf-8')\n",
    "\n",
    "# Load your trained model\n",
    "model = tf.keras.models.load_model('food_classification_model.keras', compile=False)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load the class indices\n",
    "with open('class_indices.json', 'r', encoding='utf-8') as f:\n",
    "    class_indices = json.load(f)\n",
    "\n",
    "# Reverse the class indices dictionary to map indices to class labels\n",
    "class_indices = {v: k for k, v in class_indices.items()}\n",
    "\n",
    "# Function to load and preprocess an image\n",
    "def load_and_preprocess_image(img_file):\n",
    "    try:\n",
    "        img = keras_image.load_img(img_file, target_size=(150, 150))\n",
    "        img_array = keras_image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array /= 255.0\n",
    "        return img_array\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error loading image: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to predict the class of an image\n",
    "def predict_image_class(model, img_array, class_indices):\n",
    "    if img_array is None:\n",
    "        return \"Unknown\"\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class_index = np.argmax(predictions)\n",
    "    predicted_class_label = class_indices.get(predicted_class_index, \"Unknown\")\n",
    "    return predicted_class_label\n",
    "\n",
    "# Calorie map for each class\n",
    "calorie_map = {\n",
    "    'samosa': 250,\n",
    "    'pizza': 300,\n",
    "    'Burger': 500,\n",
    "    'idli':150,\n",
    "    'kulfi':206\n",
    "    \n",
    "}\n",
    "\n",
    "# Function to calculate recommended calories\n",
    "def get_recommended_calories(age, gender, height, weight, activity_level, goal):\n",
    "    if gender.lower() == 'male':\n",
    "        bmr = 10 * weight + 6.25 * height - 5 * age + 5\n",
    "    else:\n",
    "        bmr = 10 * weight + 6.25 * height - 5 * age - 161\n",
    "\n",
    "    activity_factors = {\n",
    "        'sedentary': 1.2,\n",
    "        'lightly active': 1.375,\n",
    "        'moderately active': 1.55,\n",
    "        'very active': 1.725,\n",
    "        'super active': 1.9\n",
    "    }\n",
    "\n",
    "    tdee = bmr * activity_factors[activity_level.lower()]\n",
    "\n",
    "    if goal.lower() == 'lose weight':\n",
    "        recommended_calories = tdee - 500\n",
    "    elif goal.lower() == 'gain weight':\n",
    "        recommended_calories = tdee + 500\n",
    "    else:\n",
    "        recommended_calories = tdee\n",
    "\n",
    "    return recommended_calories\n",
    "\n",
    "# Function to calculate calorie difference\n",
    "def calculate_calorie_difference(recommended_calories, consumed_calories):\n",
    "    return recommended_calories - consumed_calories\n",
    "\n",
    "# Function to provide dietary recommendation\n",
    "def provide_dietary_recommendation(calorie_difference):\n",
    "    if calorie_difference > 0:\n",
    "        return \"You have remaining calories for the day. Consider consuming a balanced meal.\"\n",
    "    elif calorie_difference < 0:\n",
    "        return \"You have exceeded your calorie intake for the day. Consider light snacks or low-calorie foods.\"\n",
    "    else:\n",
    "        return \"You have met your calorie intake for the day. Maintain a balanced diet.\"\n",
    "\n",
    "# Main Streamlit app\n",
    "def main():\n",
    "    st.title(\"Food Classifier and Calorie Counter\")\n",
    "\n",
    "    # Sidebar for user information\n",
    "    st.sidebar.title(\"User Information\")\n",
    "    name = st.sidebar.text_input(\"Name\", \"John Doe\")\n",
    "    age = st.sidebar.number_input(\"Age\", min_value=0, max_value=150, value=30)\n",
    "    gender = st.sidebar.selectbox(\"Gender\", [\"Male\", \"Female\"])\n",
    "    height = st.sidebar.number_input(\"Height (cm)\", min_value=0, max_value=300, value=175)\n",
    "    weight = st.sidebar.number_input(\"Weight (kg)\", min_value=0, max_value=500, value=70)\n",
    "    activity_level = st.sidebar.selectbox(\"Activity Level\", [\"Sedentary\", \"Lightly Active\", \"Moderately Active\", \"Very Active\", \"Super Active\"])\n",
    "    goal = st.sidebar.selectbox(\"Goal\", [\"Lose Weight\", \"Maintain Weight\", \"Gain Weight\"])\n",
    "\n",
    "    # File uploader for image\n",
    "    st.title(\"Upload an image of the dish\")\n",
    "    uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        # Display the image\n",
    "        st.image(uploaded_file, caption=\"Uploaded Image.\", use_column_width=True)\n",
    "\n",
    "        # Perform classification and calorie counting\n",
    "        img_array = load_and_preprocess_image(uploaded_file)\n",
    "        predicted_class = predict_image_class(model, img_array, class_indices)\n",
    "        consumed_calories = calorie_map.get(predicted_class, 0)\n",
    "        recommended_calories = get_recommended_calories(age, gender, height, weight, activity_level, goal)\n",
    "        calorie_difference = calculate_calorie_difference(recommended_calories, consumed_calories)\n",
    "        dietary_recommendation = provide_dietary_recommendation(calorie_difference)\n",
    "\n",
    "        # Display results\n",
    "        st.title(\"Result\")\n",
    "        st.write(f'The image is classified as: {predicted_class}')\n",
    "        st.write(f'Calories in the dish: {consumed_calories}')\n",
    "        st.write(f'Recommended daily calorie intake: {recommended_calories}')\n",
    "        st.write(f'Calorie difference: {calorie_difference}')\n",
    "        st.write(f'Dietary recommendation: {dietary_recommendation}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# Write the content to a new Python file\n",
    "with open(\"diet_planner_app.py\", \"w\") as file:\n",
    "    file.write(streamlit_app_code)\n",
    "\n",
    "print(\"diet_planner_app.py has been created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a506c4b-4d20-4370-a524-d23057b0e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run diet_planner_app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbe09b1-7ae4-4120-a38b-e31903516c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a14bbb-e9b6-4281-abf8-897c4bfb5caf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
